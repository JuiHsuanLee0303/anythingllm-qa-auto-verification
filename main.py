import os
import requests
from dotenv import load_dotenv
import json
import uuid
from datetime import datetime
from excel_handler import ExcelHandler
from bert_score import score
from sentence_transformers import SentenceTransformer, util
import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict, Tuple, Optional
import pandas as pd
from tqdm import tqdm
import argparse
import glob

from config import Config
from logger import Logger
from similarity_analyzer import SimilarityAnalyzer

# Load environment variables
load_dotenv()

# Initialize configuration
config = Config.load_from_env()

# Initialize BERT model for semantic similarity
model = SentenceTransformer(config.MODEL_NAME)

class QAVerificationSystem:
    def __init__(self):
        self.config = Config.load_from_env()
        self.logger = Logger("qa_verification")
        self.similarity_analyzer = SimilarityAnalyzer(self.config.MODEL_NAME)
    
    def get_workspace_slug(self, workspace_name: str) -> Optional[str]:
        """ç²å–å·¥ä½œå€çš„ slug"""
        try:
            self.logger.info(f"ğŸ” æœå°‹å·¥ä½œå€: {workspace_name}")
            response = requests.get(
                f'{self.config.API_BASE_URL}/api/v1/workspaces',
                headers=self.config.get_headers()
            )
            response.raise_for_status()
            workspaces = response.json()
            
            if isinstance(workspaces, list):
                for workspace in workspaces:
                    if isinstance(workspace, dict) and workspace.get('name') == workspace_name:
                        return workspace.get('slug')
            elif isinstance(workspaces, dict):
                workspace_list = workspaces.get('workspaces', [])
                for workspace in workspace_list:
                    if workspace.get('name') == workspace_name:
                        return workspace.get('slug')
            
            self.logger.warning(f"å·¥ä½œå€ '{workspace_name}' æœªæ‰¾åˆ°")
            return None
        except Exception as e:
            self.logger.error(f"ç²å–å·¥ä½œå€æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=e)
            return None
    
    def send_chat_message(self, workspace_slug: str, message: str) -> Optional[Dict]:
        """ç™¼é€èŠå¤©è¨Šæ¯åˆ°æŒ‡å®šå·¥ä½œå€"""
        try:
            session_id = str(uuid.uuid4())
            payload = {
                "message": message,
                "mode": "query",
                "sessionId": session_id,
                "reset": False
            }
            
            self.logger.info(f"ğŸ“¤ ç™¼é€è¨Šæ¯åˆ°å·¥ä½œå€: {workspace_slug}")
            response = requests.post(
                f'{self.config.API_BASE_URL}/api/v1/workspace/{workspace_slug}/chat',
                headers=self.config.get_headers(),
                json=payload
            )
            response.raise_for_status()
            return response.json()
        except Exception as e:
            self.logger.error(f"èŠå¤©æ“ä½œæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=e)
            return None
    
    def process_qa_pairs(self, workspace_slug: str, excel_handler: ExcelHandler) -> List[Dict[str, float]]:
        """è™•ç†å•ç­”å°ä¸¦è¿”å›ç›¸ä¼¼åº¦åˆ†æ•¸"""
        all_similarity_scores = []
        all_qa_pairs = excel_handler.get_all_qa_pairs()
        
        total_qa_pairs = sum(len(qa_pairs) for qa_pairs in all_qa_pairs.values())
        
        with tqdm(total=total_qa_pairs, desc="è™•ç†å•ç­”å°", unit="å°") as pbar:
            for sheet_name, qa_pairs in all_qa_pairs.items():
                self.logger.info(f"\nğŸ“‹ è™•ç†å·¥ä½œè¡¨: {sheet_name}")
                
                for row_index, (question, excel_answer) in enumerate(qa_pairs):
                    self.logger.info(f"\nâ“ å•é¡Œ: {question}")
                    
                    response = self.send_chat_message(workspace_slug, question)
                    if response and 'textResponse' in response:
                        llm_response = response['textResponse']
                        similarity_scores = self.similarity_analyzer.calculate_similarity(
                            llm_response, excel_answer
                        )
                        all_similarity_scores.append(similarity_scores)
                        
                        excel_handler.write_llm_response(sheet_name, row_index, llm_response)
                        excel_handler.write_similarity_scores(sheet_name, row_index, similarity_scores)
                    else:
                        self.logger.warning("âŒ ç„¡æ³•ç²å– LLM å›ç­”")
                    
                    pbar.update(1)
        
        return all_similarity_scores
    
    def upload_documents(self, workspace_slug: str, directory: str) -> bool:
        """ä¸Šå‚³æŒ‡å®šç›®éŒ„ä¸­çš„æ‰€æœ‰æ–‡ä»¶åˆ° AnythingLLM"""
        try:
            self.logger.info(f"ğŸ“¤ é–‹å§‹ä¸Šå‚³æ–‡ä»¶å¾ç›®éŒ„: {directory}")
            
            file_paths = []
            for ext in self.config.SUPPORTED_MIME_TYPES.keys():
                file_paths.extend(glob.glob(os.path.join(directory, ext)))
            
            if not file_paths:
                self.logger.warning(f"åœ¨ç›®éŒ„ {directory} ä¸­æœªæ‰¾åˆ°ä»»ä½•æ”¯æ´çš„æ–‡ä»¶")
                return False
            
            success_count = 0
            for file_path in tqdm(file_paths, desc="ä¸Šå‚³æ–‡ä»¶", unit="å€‹"):
                try:
                    with open(file_path, 'rb') as f:
                        file_name = os.path.basename(file_path)
                        file_ext = os.path.splitext(file_name)[1].lower()
                        mime_type = self.config.SUPPORTED_MIME_TYPES.get(f'*{file_ext}', 'application/octet-stream')
                        
                        files = {'file': (file_name, f, mime_type)}
                        data = {
                            'addToWorkspaces': workspace_slug
                        }
                        
                        headers = self.config.get_headers()
                        headers.pop('Content-Type', None)  # ç§»é™¤ Content-Typeï¼Œè®“ requests è‡ªå‹•è¨­ç½®
                        
                        response = requests.post(
                            f'{self.config.API_BASE_URL}/api/v1/document/upload',
                            headers=headers,
                            files=files,
                            data=data
                        )
                        response.raise_for_status()
                        success_count += 1
                        self.logger.info(f"âœ… æˆåŠŸä¸Šå‚³æ–‡ä»¶: {file_name}")
                except Exception as e:
                    self.logger.error(f"âŒ ä¸Šå‚³æ–‡ä»¶ {os.path.basename(file_path)} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            
            self.logger.info(f"ğŸ“Š æ–‡ä»¶ä¸Šå‚³å®Œæˆ: æˆåŠŸ {success_count}/{len(file_paths)} å€‹æ–‡ä»¶")
            return success_count > 0
            
        except Exception as e:
            self.logger.error(f"âŒ æ–‡ä»¶ä¸Šå‚³éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=e)
            return False

    def run(self, workspace_name: str, excel_file: str, upload_dir: Optional[str] = None):
        """é‹è¡Œ QA é©—è­‰ç³»çµ±"""
        try:
            # ç²å–å·¥ä½œå€ slug
            workspace_slug = self.get_workspace_slug(workspace_name)
            if not workspace_slug:
                return
            
            self.logger.info(f"âœ… æ‰¾åˆ°å·¥ä½œå€: {workspace_slug}")
            
            # å¦‚æœæŒ‡å®šäº†ä¸Šå‚³ç›®éŒ„ï¼Œå…ˆä¸Šå‚³æ–‡ä»¶
            if upload_dir:
                if not self.upload_documents(workspace_slug, upload_dir):
                    self.logger.warning("âš ï¸ æ–‡ä»¶ä¸Šå‚³æœªå®Œæˆï¼Œä½†å°‡ç¹¼çºŒé€²è¡Œ QA é©—è­‰")
            
            # åˆå§‹åŒ– Excel è™•ç†å™¨
            excel_handler = ExcelHandler(excel_file)
            
            # è™•ç†å•ç­”å°
            similarity_scores = self.process_qa_pairs(workspace_slug, excel_handler)
            
            # ç”Ÿæˆç›¸ä¼¼åº¦åˆ†æåœ–è¡¨
            if similarity_scores:
                self.logger.info("\nğŸ“Š ç”Ÿæˆçµ±è¨ˆåœ–è¡¨...")
                self.similarity_analyzer.generate_charts(
                    similarity_scores,
                    self.config.OUTPUT_DIR
                )
        
        except FileNotFoundError:
            self.logger.error(f"âŒ éŒ¯èª¤: {excel_file} æª”æ¡ˆä¸å­˜åœ¨")
        except Exception as e:
            self.logger.error(f"âŒ éŒ¯èª¤: {str(e)}", exc_info=e)

def parse_arguments():
    """è§£æå‘½ä»¤åˆ—åƒæ•¸"""
    parser = argparse.ArgumentParser(description='QA é©—è­‰ç³»çµ±')
    parser.add_argument('-w', '--workspace', 
                      default=Config.DEFAULT_WORKSPACE,
                      help='AnythingLLM workspace åç¨±')
    parser.add_argument('-e', '--excel', 
                      default=Config.DEFAULT_EXCEL,
                      help='Excel æª”æ¡ˆåç¨±')
    parser.add_argument('-d', '--directory',
                      help='è¦ä¸Šå‚³åˆ° AnythingLLM çš„æ–‡ä»¶ç›®éŒ„è·¯å¾‘')
    return parser.parse_args()

if __name__ == "__main__":
    args = parse_arguments()
    system = QAVerificationSystem()
    system.run(args.workspace, args.excel, args.directory)
